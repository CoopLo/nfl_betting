{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "def get_data(target):\n",
    "    target = target.upper()\n",
    "    df = pd.read_csv('./scraped_data/elo_pfr_betting_data.csv', low_memory=False)\n",
    "    \n",
    "    # Prediction O/U\n",
    "    if(target == 'OU_RESULT'): # Classification\n",
    "        df['OU_RESULT'] = df['ou_result'].apply(lambda x: 0 if(x == 'U') else 1 if(x == 'O') else 2)\n",
    "        task = 'classification'\n",
    "    if(target == 'OU_LINE'): # Regression\n",
    "        df['OU_RESULT'] = df['ou_result'].apply(lambda x: 0 if(x == 'U') else 1 if(x == 'O') else 2)\n",
    "        df['OU_LINE'] = df['ou_line']\n",
    "        df['FINAL_OU'] = df['score1'] + df['score2']\n",
    "        task = 'regression'\n",
    "        target = 'FINAL_OU'\n",
    "        \n",
    "    if('OU' in target):\n",
    "        df = df.dropna(subset=[target])\n",
    "        df = df[df['OU_RESULT'] != 2]\n",
    "        outcome = None if(task == 'classification') else ['OU_LINE', 'OU_RESULT']\n",
    "        \n",
    "    if(target == 'SPREAD_RESULT'): # Classification\n",
    "        df['SPREAD_RESULT'] = df['spread_result'].apply(lambda x: 0 if(x == 'L') else 1 if(x == 'W') else 2)\n",
    "        task = 'classification'\n",
    "    if(target == 'SPREAD'): # Regression\n",
    "        df['SPREAD_RESULT'] = df['spread_result'].apply(lambda x: 0 if(x == 'L') else 1 if(x == 'W') else 2)\n",
    "        df['SPREAD'] = df['spread']\n",
    "        df['FINAL_SPREAD'] = df['score1'] - df['score2']\n",
    "        task = 'regression'\n",
    "        target = 'FINAL_SPREAD'\n",
    "\n",
    "    if('SPREAD' in target):\n",
    "        df = df.dropna(subset=[target])\n",
    "        df = df[df['SPREAD_RESULT'] != 2]\n",
    "        outcome = None if(task == 'classification') else ['SPREAD', 'SPREAD_RESULT']\n",
    "    \n",
    "    return df, target.upper(), outcome, task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(df, target):\n",
    "    game_data_columns = []\n",
    "    for c in df.columns:\n",
    "        if(\"home\" in c or \"away\" in c or 'elo' in c):\n",
    "            if('td' not in c and 'xp' not in c and 'fg' not in c and 'poss' not in c and 'down' not in c and target not in c and 'post' not in c):\n",
    "                game_data_columns.append(c)\n",
    "\n",
    "    return df[game_data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset that pytorch loader can work with \n",
    "class NFLClassificationDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, task='classification', outcome=None):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        if(task == 'classification'):\n",
    "            self.y = torch.tensor(dataframe[target].values).long()\n",
    "            self.outcome = torch.tensor(dataframe[target].values).long()\n",
    "        else:\n",
    "            self.y = torch.tensor(dataframe[target].values).float()\n",
    "            self.outcome = torch.tensor(dataframe[outcome].values).float()\n",
    "\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target, task, year=2020, outcome=None):\n",
    "    '''\n",
    "        Uses single year as validaion year. Previous years are train, future years are test\n",
    "    '''\n",
    "    df_train = benchmark_data[df['year'] <= year].copy()\n",
    "    df_val = benchmark_data[df['year'] == year].copy()\n",
    "    df_test = benchmark_data[df['year'] > year].copy()\n",
    "    \n",
    "    df_train[target] = df[df['year'] < year][target]\n",
    "    df_val[target] = df[df['year'] == year][target]\n",
    "    df_test[target] = df[df['year'] > year][target]\n",
    "\n",
    "    for c in df_train.columns:\n",
    "        if(task == 'classification' and c == target):\n",
    "            continue\n",
    "        mean = df_train[c].mean()\n",
    "        stdev = df_train[c].std()\n",
    "\n",
    "        df_train[c] = (df_train[c] - mean) / stdev\n",
    "        df_val[c] = (df_val[c] - mean) / stdev\n",
    "        df_test[c] = (df_test[c] - mean) / stdev\n",
    "    \n",
    "    df_train = df_train.dropna(subset=[target])\n",
    "    df_val = df_val.dropna(subset=[target])\n",
    "    df_test = df_test.dropna(subset=[target])\n",
    "    \n",
    "    if(outcome is not None):\n",
    "        df_train[outcome] = df[df['year'] < year][outcome]\n",
    "        df_val[outcome] = df[df['year'] == year][outcome]\n",
    "        df_test[outcome] = df[df['year'] > year][outcome]\n",
    "        \n",
    "        mean = df_train[outcome[0]].mean()\n",
    "        std = df_train[outcome[0]].std()\n",
    "        \n",
    "        df_train[outcome[0]] = (df_train[outcome[0]] - mean)/std\n",
    "        df_val[outcome[0]] = (df_val[outcome[0]] - mean)/std\n",
    "        df_test[outcome[0]] = (df_test[outcome[0]] - mean)/std\n",
    "\n",
    "    \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "def get_data_loaders(df_train, df_val, df_test, target, task, batch_size=32, outcome=None):\n",
    "    features = list(df_train.columns.difference([target]))\n",
    "    train_dataset = NFLClassificationDataset(df_train, target=target, features=features, task=task, outcome=outcome)\n",
    "    val_dataset = NFLClassificationDataset(df_val, target=target, features=features, task=task, outcome=outcome)\n",
    "    test_dataset = NFLClassificationDataset(df_test, target=target, features=features, task=task, outcome=outcome)\n",
    "    \n",
    "    # Set the dataset in pytorch dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "def train(data, model, loss_func, optimizer, task):\n",
    "    n_batches = len(data)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for x,y in data:\n",
    "        output= model(x)\n",
    "        if(task=='classification'):\n",
    "            loss = loss_func(output, y)\n",
    "        if(task=='regression'):\n",
    "            loss = loss_func(output, y[:,np.newaxis])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    mean_loss = total_loss/n_batches\n",
    "    return mean_loss, model\n",
    "    \n",
    "\n",
    "def test(data, model, loss_func, task):\n",
    "    n_batches = len(data)\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            output = model(x)\n",
    "            if(task == 'classification'):\n",
    "                total_loss += loss_func(output,y).item()\n",
    "            else:\n",
    "                total_loss += loss_func(output,y[:,np.newaxis]).item()\n",
    "            \n",
    "    mean_loss = total_loss/n_batches\n",
    "    \n",
    "    return mean_loss   \n",
    "\n",
    "# prediction function\n",
    "def predict(data, model):\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X,_ in data:\n",
    "            y_fit = model(X)\n",
    "            output = torch.cat((output,y_fit), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, model):\n",
    "    preds, labels = torch.Tensor([]), torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            labels = torch.cat((labels, y))\n",
    "            preds = torch.cat((preds, torch.argmax(model(x[np.newaxis]), dim=2)[0]))            \n",
    "            \n",
    "    acc = 100*sum(np.array(preds) == np.array(labels))/len(preds)\n",
    "    print(\"CLASSIFICATION ACCURACY: {0:.3f}%\".format(acc))\n",
    "    return acc\n",
    "\n",
    "def classification_betting_result(model, test_loader, threshold=0.6):\n",
    "    print(\"THRESHOLD: {}\".format(threshold))\n",
    "    with torch.no_grad():\n",
    "        good_bet = 0\n",
    "        bad_bet = 0\n",
    "        money = 0\n",
    "        total_games = 0\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x)\n",
    "            pred_label = torch.argmax(model(x), dim=1)\n",
    "            for i in range(len(pred)):\n",
    "                if(pred[i][pred_label[i]] > threshold):\n",
    "                    if(pred_label[i] == y[i]):\n",
    "                        good_bet += 1\n",
    "                        money += 90.91\n",
    "                    else:\n",
    "                        bad_bet += 1\n",
    "                        money -= 100\n",
    "                total_games += 1\n",
    "\n",
    "    print(\"GOOD BETS: {}\\tBAD BETS: {}\".format(good_bet, bad_bet))\n",
    "    print(\"MONEY MADE: {0:.2f} BETTING ON {1:.2f}% OF GAMES\".format(money, 100*(bad_bet+good_bet)/total_games))\n",
    "    return money, (bad_bet+good_bet)/total_games\n",
    "\n",
    "\n",
    "def regression_betting_result(model, test_loader, threshold=0.6):\n",
    "    print(\"THRESHOLD: {}\".format(threshold))\n",
    "    with torch.no_grad():\n",
    "        good_bet = 0\n",
    "        bad_bet = 0\n",
    "        money = 0\n",
    "        total_games = 0\n",
    "        preds, ou_preds = torch.Tensor([]), torch.Tensor([])\n",
    "        \n",
    "        # Get predictions\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x)\n",
    "            preds = torch.cat((preds, pred[:,0]))\n",
    "\n",
    "        # Check if prediction is bigger or smaller than line\n",
    "        outcome = test_loader.dataset.outcome\n",
    "        meets_threshold, ou_preds = [], []\n",
    "        for i in range(len(preds)):\n",
    "            meets_threshold.append((preds[i] - outcome[i][0]).abs() > threshold)\n",
    "            ou_preds.append(preds[i] > outcome[i][0])\n",
    "\n",
    "        for i in range(len(ou_preds)):\n",
    "            if(meets_threshold[i]):\n",
    "                if(ou_preds[i] == outcome[i][1]):\n",
    "                    good_bet += 1\n",
    "                    money += 90.91\n",
    "                else:\n",
    "                    bad_bet += 1\n",
    "                    money -= 100\n",
    "            total_games += 1\n",
    "\n",
    "    print(\"GOOD BETS: {}\\tBAD BETS: {}\".format(good_bet, bad_bet))\n",
    "    print(\"MONEY MADE: {0:.2f} BETTING ON {1:.2f}% OF GAMES\".format(money, 100*(bad_bet+good_bet)/total_games))\n",
    "    return money, (bad_bet+good_bet)/total_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 8 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD: 1.0\n",
      "GOOD BETS: 66\tBAD BETS: 74\n",
      "MONEY MADE: -1399.94 BETTING ON 57.14% OF GAMES\n"
     ]
    }
   ],
   "source": [
    "# Get data    \n",
    "target = 'ou_line'\n",
    "df, target, outcome, task = get_data(target)\n",
    "benchmark_data = get_columns(df, target)\n",
    "\n",
    "df_train, df_val, df_test = split_data(df, target, task, outcome=outcome)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders(\n",
    "                                            df_train,\n",
    "                                            df_val,\n",
    "                                            df_test, \n",
    "                                            target,\n",
    "                                            task,\n",
    "                                            batch_size=32,\n",
    "                                            outcome=outcome)\n",
    "\n",
    "thresholds = np.linspace(0.5, 1.0, 51)\n",
    "money_made = []\n",
    "games_bet = []\n",
    "\n",
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "epoch = 20\n",
    "input_size = len(list(df_train.columns.difference([target])))\n",
    "hidden_size = 64\n",
    "dropout = 0.2\n",
    "\n",
    "if(task == 'classification'):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, 64),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,2),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "elif(task == 'regression'):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, 64),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,1),\n",
    "    )\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Run lstm \n",
    "trainloss = []\n",
    "testloss = []\n",
    "valloss = []\n",
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "for i in tqdm(range(epoch)):\n",
    "    train_loss, model = train(train_loader, model, loss_func, optimizer=optimizer, task=task)\n",
    "    trainloss.append(train_loss)\n",
    "\n",
    "    val_loss = test(val_loader, model, loss_func, task=task)\n",
    "    valloss.append(val_loss)\n",
    "\n",
    "    test_loss  = test(test_loader, model, loss_func, task=task)\n",
    "    testloss.append(test_loss)    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainloss)\n",
    "ax.plot(valloss)\n",
    "ax.plot(testloss)\n",
    "plt.show()\n",
    "\n",
    "if(task == 'classification'):\n",
    "    val_accuracy = evaluate(val_loader, model)\n",
    "    test_accuracy = evaluate(test_loader, model)\n",
    "    result = classification_betting_result(model, val_loader, threshold=0.7)\n",
    "    money_made.append(result[0])\n",
    "    games_bet.append(result[1])\n",
    "elif(task == 'regression'):\n",
    "    result = regression_betting_result(model, val_loader, threshold=1.)\n",
    "    money_made.append(result[0])\n",
    "    games_bet.append(result[1])\n",
    "        \n",
    "#fig, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "#ax[0].plot(thresholds, money_made)\n",
    "#ax[1].plot(thresholds, games_bet)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "def get_lstm_data(target):\n",
    "    target = target.upper()\n",
    "    df = pd.read_csv('./scraped_data/elo_pfr_betting_data.csv', low_memory=False)\n",
    "    df = df[df['season'] >= 1979]\n",
    "\n",
    "    # Prediction O/U\n",
    "    if(target == 'OU_RESULT'): # Classification\n",
    "        df['OU_RESULT'] = df['ou_result'].apply(lambda x: 0 if(x == 'U') else 1 if(x == 'O') else 2)\n",
    "        task = 'classification'\n",
    "    if(target == 'OU_LINE'): # Regression\n",
    "        df['OU_RESULT'] = df['ou_result'].apply(lambda x: 0 if(x == 'U') else 1 if(x == 'O') else 2)\n",
    "        df['OU_LINE'] = df['ou_line']\n",
    "        df['FINAL_OU'] = df['score1'] + df['score2']\n",
    "        task = 'regression'\n",
    "        target = 'FINAL_OU'\n",
    "        \n",
    "    if('OU' in target):\n",
    "        df = df.dropna(subset=[target])\n",
    "        df = df[df['OU_RESULT'] != 2]\n",
    "        outcome = None if(task == 'classification') else ['OU_LINE', 'OU_RESULT']\n",
    "        \n",
    "    if(target == 'SPREAD_RESULT'): # Classification\n",
    "        df['SPREAD_RESULT'] = df['spread_result'].apply(lambda x: 0 if(x == 'L') else 1 if(x == 'W') else 2)\n",
    "        task = 'classification'\n",
    "    if(target == 'SPREAD'): # Regression\n",
    "        df['SPREAD_RESULT'] = df['spread_result'].apply(lambda x: 0 if(x == 'L') else 1 if(x == 'W') else 2)\n",
    "        df['SPREAD'] = df['spread']\n",
    "        df['FINAL_SPREAD'] = df['score1'] - df['score2']\n",
    "        task = 'regression'\n",
    "        target = 'FINAL_SPREAD'\n",
    "\n",
    "    if('SPREAD' in target):\n",
    "        df = df.dropna(subset=[target])\n",
    "        df = df[df['SPREAD_RESULT'] != 2]\n",
    "        outcome = None if(task == 'classification') else ['SPREAD', 'SPREAD_RESULT']\n",
    "        \n",
    "    return df, target.upper(), outcome, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFLSingleTeamData(Dataset):\n",
    "    def __init__(self, dataframe, target, features, task='classification', outcome=None):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.index = dataframe.index\n",
    "        if(task == 'classification'):\n",
    "            self.y = torch.tensor(dataframe[target].values).long()\n",
    "            self.outcome = torch.tensor(dataframe[target].values).long()\n",
    "        else:\n",
    "            self.y = torch.tensor(dataframe[target].values).float()\n",
    "            self.outcome = torch.tensor(dataframe[outcome].values).float()\n",
    "\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class SeasonRegressionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, dropout):\n",
    "        super(SeasonRegressionLSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
    "                            hidden_size=self.hidden_size, \n",
    "                            num_layers = self.num_layers, \n",
    "                            dropout = self.dropout, \n",
    "                            batch_first = True)#.cuda()\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=output_size)#.cuda()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, self.hidden_size).requires_grad_()#.cuda()\n",
    "        c0 = torch.zeros(self.num_layers, self.hidden_size).requires_grad_()#.cuda()\n",
    "        \n",
    "        outs, (hn, cn) = self.lstm(x,(h0,c0))\n",
    "        out = self.linear(outs)\n",
    "        if(out.shape[1] == 2):\n",
    "            out = nn.Softmax(dim=1)(out)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lstm_data(df, target, task, year=2020, outcome=None):\n",
    "    '''\n",
    "        Uses single year as validaion year. Previous years are train, future years are test\n",
    "    '''\n",
    "    df_train = benchmark_data[df['season'] <= year].copy()\n",
    "    df_val = benchmark_data[df['season'] == year].copy()\n",
    "    df_test = benchmark_data[df['season'] > year].copy()\n",
    "    \n",
    "    df_train[target] = df[df['season'] < year][target]\n",
    "    df_val[target] = df[df['season'] == year][target]\n",
    "    df_test[target] = df[df['season'] > year][target]\n",
    "\n",
    "    for c in df_train.columns:\n",
    "        if(task == 'classification' and c == target):\n",
    "            continue\n",
    "        mean = df_train[c].mean()\n",
    "        stdev = df_train[c].std()\n",
    "\n",
    "        df_train[c] = (df_train[c] - mean) / stdev\n",
    "        df_val[c] = (df_val[c] - mean) / stdev\n",
    "        df_test[c] = (df_test[c] - mean) / stdev\n",
    "    \n",
    "    df_train = df_train.dropna(subset=[target])\n",
    "    df_val = df_val.dropna(subset=[target])\n",
    "    df_test = df_test.dropna(subset=[target])\n",
    "    \n",
    "    if(outcome is not None):\n",
    "        df_train[outcome] = df[df['season'] < year][outcome]\n",
    "        df_val[outcome] = df[df['season'] == year][outcome]\n",
    "        df_test[outcome] = df[df['season'] > year][outcome]\n",
    "        \n",
    "        mean = df_train[outcome[0]].mean()\n",
    "        std = df_train[outcome[0]].std()\n",
    "        \n",
    "        df_train[outcome[0]] = (df_train[outcome[0]] - mean)/std\n",
    "        df_val[outcome[0]] = (df_val[outcome[0]] - mean)/std\n",
    "        df_test[outcome[0]] = (df_test[outcome[0]] - mean)/std\n",
    "\n",
    "    \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "def _shift_one_week(team_season, target):\n",
    "    N = len(team_season)\n",
    "    shifted = np.empty(N)\n",
    "    shifted[:] = np.nan\n",
    "    shifted[:N-1] = team_season[target][1:]\n",
    "    team_season[target] = shifted\n",
    "    return team_season.dropna()\n",
    "\n",
    "\n",
    "def get_lstm_data_loaders(df, df_train, df_val, df_test, target, task, batch_size=4, outcome=None, year=2020):\n",
    "    features = list(df_train.columns.difference([target]))\n",
    "    train_data, val_data, test_data = [], [], []\n",
    "    for season, games in df.groupby(\"season\"):\n",
    "        # Need each team's games for each season, which becomes an NFLSingleTeamData object\n",
    "        # Need to shift data by 1 game here.\n",
    "        for team in games['team1'].unique():\n",
    "            if(season < year):\n",
    "                team_season = df_train.loc[games[(games[\"team1\"] == team) | (games[\"team2\"] == team)].index]\n",
    "                team_season = _shift_one_week(team_season, target)\n",
    "                train_data.append(NFLSingleTeamData(team_season, target=target, features=features, task=task, outcome=outcome))\n",
    "            elif(season == year):\n",
    "                team_season = df_val.loc[games[(games[\"team1\"] == team) | (games[\"team2\"] == team)].index]\n",
    "                team_season = _shift_one_week(team_season, target)\n",
    "                val_data.append(NFLSingleTeamData(team_season, target=target, features=features, task=task, outcome=outcome))\n",
    "            else:\n",
    "                team_season = df_test.loc[games[(games[\"team1\"] == team) | (games[\"team2\"] == team)].index]\n",
    "                team_season = _shift_one_week(team_season, target)\n",
    "                test_data.append(NFLSingleTeamData(team_season, target=target, features=features, task=task, outcome=outcome))\n",
    "                \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "def train_lstm(data, model, loss_func, optimizer, task):\n",
    "    n_batches = len(data)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for d in data:\n",
    "        output = model(d.X)#.cuda())\n",
    "        if(task=='classification'):\n",
    "            loss = loss_func(output, d.y)#.cuda())\n",
    "        if(task=='regression'):\n",
    "            loss = loss_func(output, d.y[:,np.newaxis])#.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    mean_loss = total_loss/n_batches\n",
    "    return mean_loss, model\n",
    "    \n",
    "\n",
    "def test_lstm(data, model, loss_func, task):\n",
    "    n_batches = len(data)\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in data:\n",
    "            output = model(d.X)#.cuda())\n",
    "            if(task == 'classification'):\n",
    "                total_loss += loss_func(output,d.y).item()#.cuda()).item()\n",
    "            else:\n",
    "                total_loss += loss_func(output,d.y[:,np.newaxis]).item()\n",
    "                #total_loss += loss_func(output,d.y.cuda()[:,np.newaxis]).item()\n",
    "            \n",
    "    mean_loss = total_loss/n_batches\n",
    "    \n",
    "    return mean_loss   \n",
    "\n",
    "# prediction function\n",
    "def predict_lstm(data, model):\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in data:\n",
    "            y_fit = model(d.X).detach()\n",
    "            #y_fit = model(d.X.cuda()).detach()\n",
    "            output = torch.cat((output,y_fit), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(data, model):\n",
    "    preds, labels = torch.Tensor([]), torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for d in data:\n",
    "            labels = torch.cat((labels, d.y))\n",
    "            preds = torch.cat((preds, torch.argmax(model(d.X), dim=1)))            \n",
    "            #preds = torch.cat((preds, torch.argmax(model(d.X.cuda()).cpu(), dim=1)))            \n",
    "            \n",
    "    acc = 100*sum(np.array(preds) == np.array(labels))/len(preds)\n",
    "    print(\"CLASSIFICATION ACCURACY: {0:.3f}%\".format(acc))\n",
    "    return acc\n",
    "\n",
    "def classification_betting_result_lstm(model, test_loader, df, threshold=0.6):\n",
    "    # Need to filter out duplicates somehow\n",
    "    print(\"THRESHOLD: {}\".format(threshold))\n",
    "    with torch.no_grad():\n",
    "        good_bet = 0\n",
    "        bad_bet = 0\n",
    "        money = 0\n",
    "        total_games = 0\n",
    "        \n",
    "        all_pred_labels, all_ys, all_indices = [], [], []\n",
    "        for d in test_loader:\n",
    "            # Get prediction and label\n",
    "            pred = model(d.X).cpu()\n",
    "            pred_label = torch.argmax(model(d.X).cpu(), dim=1)\n",
    "            \n",
    "            # Hold on to prediction/data if above threshold\n",
    "            for idx in range(len(pred)):\n",
    "                total_games += 1\n",
    "                if(pred[idx][pred_label[idx]] > threshold):\n",
    "                    all_pred_labels.append(float(pred_label[idx]))\n",
    "                    all_ys.append(float(d.y[idx]))\n",
    "                    all_indices.append(float(d.index[idx]))\n",
    "\n",
    "        # Match make_bet between games predicted from each team\n",
    "        pred_dict = {}\n",
    "        for i in range(len(all_pred_labels)):\n",
    "            if(all_indices[i] not in pred_dict):\n",
    "                pred_dict[all_indices[i]] = [all_pred_labels[i]]\n",
    "            else:\n",
    "                pred_dict[all_indices[i]].append(all_pred_labels[i])\n",
    "        \n",
    "        # Do bets\n",
    "        for i in range(len(all_pred_labels)):\n",
    "            # Don't bet on games with opposite predictions\n",
    "            if(len(pred_dict[all_indices[i]]) == 2 and sum(pred_dict[all_indices[i]]) != 2):\n",
    "                continue\n",
    "            if(all_pred_labels[i] == all_ys[i]):\n",
    "                if(len(pred_dict[all_indices[i]]) == 2):\n",
    "                    money += 90.91/2\n",
    "                    good_bet += 1/2\n",
    "                else:\n",
    "                    money += 90.91\n",
    "                    good_bet += 1\n",
    "            else:\n",
    "                if(len(pred_dict[all_indices[i]]) == 2):\n",
    "                    bad_bet += 12\n",
    "                    money -= 100/2\n",
    "                else:\n",
    "                    bad_bet += 1\n",
    "                    money -= 100\n",
    "\n",
    "    print(\"GOOD BETS: {}\\tBAD BETS: {}\".format(good_bet, bad_bet))\n",
    "    print(\"MONEY MADE: {0:.2f} BETTING ON {1:.2f}% OF GAMES\".format(money, 100*(bad_bet+good_bet)/total_games))\n",
    "    return money, (bad_bet+good_bet)/total_games\n",
    "\n",
    "\n",
    "def regression_betting_result_lstm(model, test_loader, df, threshold=0.6):\n",
    "    # Need to filter out duplicates somehow\n",
    "    print(\"THRESHOLD: {}\".format(threshold))\n",
    "    with torch.no_grad():\n",
    "        good_bet = 0\n",
    "        bad_bet = 0\n",
    "        money = 0\n",
    "        total_games = 0\n",
    "        preds, ou_preds = torch.Tensor([]), torch.Tensor([])\n",
    "        all_indices = []\n",
    "        \n",
    "        # Get predictions\n",
    "        pred_dict = {}\n",
    "        for d in test_loader:\n",
    "            pred = model(d.X)\n",
    "            preds = torch.cat((preds, pred[:,0]))\n",
    "            for i in range(len(pred)):\n",
    "                all_indices.append(d.index[i])\n",
    "\n",
    "        # Check if prediction is bigger or smaller than line\n",
    "        outcome = torch.Tensor([])\n",
    "        for d in test_loader:\n",
    "            outcome = torch.cat((outcome, d.outcome))\n",
    "\n",
    "        meets_threshold, ou_preds = [], []\n",
    "        for i in range(len(preds)):\n",
    "            meets_threshold.append((preds[i] - outcome[i][0]).abs() > threshold)\n",
    "            ou_preds.append(preds[i] > outcome[i][0])\n",
    "            \n",
    "        # Match make_bet between games predicted from each team\n",
    "        pred_dict = {}\n",
    "        for i in range(len(all_indices)):\n",
    "            if(all_indices[i] not in pred_dict):\n",
    "                pred_dict[all_indices[i]] = [int(meets_threshold[i])]\n",
    "            else:\n",
    "                pred_dict[all_indices[i]].append(int(meets_threshold[i]))\n",
    "                \n",
    "        # Do bets\n",
    "        for i in range(len(ou_preds)):\n",
    "            if(len(pred_dict[all_indices[i]]) == 2 and sum(pred_dict[all_indices[i]]) != 2):\n",
    "                continue\n",
    "            if(meets_threshold[i]):\n",
    "                if(ou_preds[i] == outcome[i][1]):\n",
    "                    good_bet += 1\n",
    "                    money += 90.91\n",
    "                else:\n",
    "                    bad_bet += 1\n",
    "                    money -= 100\n",
    "            total_games += 1\n",
    "\n",
    "    print(\"GOOD BETS: {}\\tBAD BETS: {}\".format(good_bet, bad_bet))\n",
    "    print(\"MONEY MADE: {0:.2f} BETTING ON {1:.2f}% OF GAMES\".format(money, 100*(bad_bet+good_bet)/total_games))\n",
    "    return money, (bad_bet+good_bet)/total_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237 32 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████▌                      | 13/20 [00:50<00:26,  3.86s/it]"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "target = 'ou_result' # One of: spread, spread_result, ou_line, ou_result\n",
    "df, target, outcome, task = get_lstm_data(target)\n",
    "benchmark_data = get_columns(df, target)\n",
    "\n",
    "df_train, df_val, df_test = split_lstm_data(df, target, task, outcome=outcome)\n",
    "#print(df_train.columns)\n",
    "#raise\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "train_loader, val_loader, test_loader = get_lstm_data_loaders(\n",
    "                                            df,\n",
    "                                            df_train,\n",
    "                                            df_val,\n",
    "                                            df_test, \n",
    "                                            target,\n",
    "                                            task,\n",
    "                                            batch_size=1,\n",
    "                                            outcome=outcome)\n",
    "\n",
    "thresholds = np.linspace(0.5, 1.0, 51)\n",
    "money_made = []\n",
    "games_bet = []\n",
    "\n",
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "epoch = 20\n",
    "input_size = len(df_train.columns)-1\n",
    "hidden_size = 32\n",
    "num_layers = 3\n",
    "dropout = 0.2\n",
    "\n",
    "model = SeasonRegressionLSTM(\n",
    "                       input_size=input_size,\n",
    "                       output_size=1 if(task == 'regression') else 2,\n",
    "                       hidden_size=hidden_size, \n",
    "                       num_layers= num_layers,\n",
    "                       dropout= dropout\n",
    "                      )#.cuda()\n",
    "loss_func = nn.CrossEntropyLoss() if(task == 'classification') else nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "# Run lstm \n",
    "trainloss = []\n",
    "testloss = []\n",
    "valloss = []\n",
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "for i in tqdm(range(epoch)):\n",
    "    train_loss, model = train_lstm(train_loader, model, loss_func, optimizer=optimizer, task=task)\n",
    "    trainloss.append(train_loss)\n",
    "\n",
    "    val_loss = test_lstm(val_loader, model, loss_func, task=task)\n",
    "    valloss.append(val_loss)\n",
    "\n",
    "    test_loss  = test_lstm(test_loader, model, loss_func, task=task)\n",
    "    testloss.append(test_loss)    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainloss)\n",
    "ax.plot(valloss)\n",
    "ax.plot(testloss)\n",
    "plt.show()\n",
    "\n",
    "if(task == 'classification'):\n",
    "    val_accuracy = evaluate_lstm(val_loader, model)\n",
    "    test_accuracy = evaluate_lstm(test_loader, model)\n",
    "    result = classification_betting_result_lstm(model, val_loader, df, threshold=0.52)\n",
    "    money_made.append(result[0])\n",
    "    games_bet.append(result[1])\n",
    "elif(task == 'regression'):\n",
    "    result = regression_betting_result_lstm(model, val_loader, df, threshold=0.1)\n",
    "    money_made.append(result[0])\n",
    "    games_bet.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
